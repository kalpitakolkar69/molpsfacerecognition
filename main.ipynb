{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Recognition Using Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mounts drive on google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "7Z_K_VIFztce",
    "outputId": "16af2eee-1656-4ba4-b931-3867320f2f6e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all necessary flies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_hZVquWBx9b"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "#from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify TensorFlow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "colab_type": "code",
    "id": "eoKSWDje_6z0",
    "outputId": "7529a824-1621-44c3-d993-0b5f92add485"
   },
   "outputs": [],
   "source": [
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")\n",
    "print(\"GPU : \",tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l9qTqaSDaL-i"
   },
   "source": [
    "### Load the data\n",
    "we'll  need to make sure the input data is resized to 224x224 or 229x229 pixels as required by the networks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPlsrKMkzKUD"
   },
   "outputs": [],
   "source": [
    "zip_file=\"/content/drive/My Drive/Celebs_Dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HA69CPvROvk5"
   },
   "source": [
    "### Prepare training and validation  dataset\n",
    "Create the training and validation directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PhB3buj3OoKP"
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.path.dirname(zip_file), 'data')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "validation_dir = os.path.join(data_dir, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "SU_PML_tzKUM",
    "outputId": "027e8df8-8d89-46c1-d2d4-1745cef528e4"
   },
   "outputs": [],
   "source": [
    "print(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bDUxGnMdkmE8"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "def count(dir, counter=0):\n",
    "    \"returns number of files in dir and subdirs\"\n",
    "    for pack in os.walk(dir):\n",
    "        for f in pack[2]:\n",
    "            counter += 1\n",
    "    return dir + \" : \" + str(counter) + \" files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "lwFeDj4ughkE",
    "outputId": "0dc5d495-e211-490a-d63f-f960b259673c"
   },
   "outputs": [],
   "source": [
    "print('total images for training :', count(train_dir))\n",
    "print('total images for validation :', count(validation_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sKbwKt0_aL_D"
   },
   "source": [
    "### Label mapping\n",
    "\n",
    "You'll also need to load in a mapping from category label to category name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "FCf_N7v3HBzB",
    "outputId": "44092b15-6d09-4526-c440-f64fd9290b7b"
   },
   "outputs": [],
   "source": [
    "classes = [\"Elon Musk\", \"Bill Gates\", \"Steve Jobs\", \"Sundar Pichai\", \"Jeff Beroz\", \"Jack Ma\", \n",
    "           \"Satya Nadela\", \"Larry Page\", \"Mark Zukerberg\", \"Arvind Krishna\"]\n",
    "    \n",
    "print (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "hzILXef8Um5v",
    "outputId": "f462022a-875a-423d-d040-27077ee9e947"
   },
   "outputs": [],
   "source": [
    "print('Number of classes:',len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5VeSPT_J0otV"
   },
   "source": [
    "### Select the Pre-trained Model to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "lyCAYjNT09ja",
    "outputId": "a860f898-235c-465c-fa27-10480ba7e67f"
   },
   "outputs": [],
   "source": [
    "module_selection = (\"mobilenet_v2\", 224, 1280)\n",
    "\n",
    "handle_base, pixels, FV_SIZE = module_selection\n",
    "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/2\".format(handle_base)\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "\n",
    "print(\"Using {} with input size {} and output dimension {}\".format(\n",
    "  MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))\n",
    "\n",
    "BATCH_SIZE = 64 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ypePvgaXw5Lm"
   },
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "##### Let's set up data generators that will read pictures in our source folders, and perform preprocessing (Data augmentation). Inputs are suitably resized for the selected module. Dataset augmentation (i.e., random distortions of an image each time it is read) improves training, esp. when fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "JRrsFKez6fFf",
    "outputId": "7907bd28-e052-4f64-a656-a7ca7185fa34"
   },
   "outputs": [],
   "source": [
    "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir, \n",
    "    shuffle=False, \n",
    "    seed=42,\n",
    "    color_mode=\"rgb\", \n",
    "    class_mode=\"categorical\",\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "do_data_augmentation = True\n",
    "if do_data_augmentation:\n",
    "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "      rescale = 1./255,\n",
    "      rotation_range=40,\n",
    "      horizontal_flip=True,\n",
    "      width_shift_range=0.2, \n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2, \n",
    "      zoom_range=0.2,\n",
    "      fill_mode='nearest' )\n",
    "else:\n",
    "  train_datagen = validation_datagen\n",
    "  \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, \n",
    "    subset=\"training\", \n",
    "    shuffle=True, \n",
    "    seed=42,\n",
    "    color_mode=\"rgb\", \n",
    "    class_mode=\"categorical\",\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Afm5Jn42E4T"
   },
   "source": [
    "### Build the model\n",
    "##### All it takes is to put a linear classifier on top of the feature_extractor_layer with the Hub module.\n",
    "\n",
    "##### For speed, we start out with a non-trainable feature_extractor_layer, but you can also enable fine-tuning for greater accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iiu7viPNdEI9"
   },
   "outputs": [],
   "source": [
    "feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
    "                                   input_shape=IMAGE_SIZE+(3,),\n",
    "                                   output_shape=[FV_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1UspO5td5r3O"
   },
   "outputs": [],
   "source": [
    "from keras.applications import MobileNet\n",
    "\n",
    "img_rows, img_cols = 224, 224 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-loads the MobileNet model without the top or FC layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MobileNet = MobileNet(weights = 'imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape = (img_rows, img_cols, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hMYytuAGB34w"
   },
   "outputs": [],
   "source": [
    "do_fine_tuning = True\n",
    "base_model = MobileNet\n",
    "if do_fine_tuning:\n",
    "    feature_extractor.trainable = True\n",
    "    for layer in base_model.layers[-30:]:\n",
    "        layer.trainable = False\n",
    "else:\n",
    "    feature_extractor.trainable = False    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For building module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "A9iG69R72XUT",
    "outputId": "7d98870a-b964-438d-d551-caa46c08636e"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    feature_extractor,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(train_generator.num_classes, activation='softmax',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGGphhh8Vu50"
   },
   "source": [
    "### Compiling Model\n",
    "##### Specify Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cq5rzR-vV7tn"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "\n",
    "model.compile(\n",
    "   optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE), \n",
    "   loss='categorical_crossentropy',\n",
    "   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ia50ckJ6-rVr"
   },
   "source": [
    "### Train model using validation dataset for validate each steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "Cf1FVwyCRI8o",
    "outputId": "346a0505-8dc3-44a2-a8f7-0db326a6c8ab"
   },
   "outputs": [],
   "source": [
    "EPOCHS=25 #@param {type:\"integer\"}\n",
    "\n",
    "history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples//validation_generator.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNzdageWS6k5"
   },
   "source": [
    "### Random test\n",
    "##### Random sample images from validation dataset and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1jIf7rKTBLx"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import itertools\n",
    "import random\n",
    "from collections import Counter\n",
    "from glob import iglob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To load random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "    img = cv2.imread(os.path.join(data_dir, validation_dir, filename))\n",
    "    img = cv2.resize(img, (IMAGE_SIZE[0], IMAGE_SIZE[1]) )\n",
    "    img = img /255\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To predict image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    probabilities = model.predict(np.asarray([img]))[0]\n",
    "    class_idx = np.argmax(probabilities)\n",
    "    \n",
    "    return {classes[class_idx]: probabilities[class_idx]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shows prediction and image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tKZduGZoTFSg",
    "outputId": "19defa92-3564-4509-e1a2-15337464b33c"
   },
   "outputs": [],
   "source": [
    "for idx, filename in enumerate(random.sample(validation_generator.filenames, 5)):\n",
    "    print(\"SOURCE: class: %s, file: %s\" % (os.path.split(filename)[0], filename))\n",
    "    \n",
    "    img = load_image(filename)\n",
    "    prediction = predict(img)\n",
    "    print(\"PREDICTED: class: %s, confidence: %f\" % (list(prediction.keys())[0], list(prediction.values())[0]))\n",
    "    plt.imshow(img)\n",
    "    plt.figure(idx)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31q93iM8ejMu"
   },
   "source": [
    "## Save the Model\n",
    "##### Now that we have trained the model, export it as a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "OxZNx2DRTolS",
    "outputId": "ed4dde1b-eadc-4a6f-834a-22dfaec8b5f8"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "\n",
    "export_path = \"/content/drive/My Drive/Face Recognition /Model/{}\".format(\"face_reco\")\n",
    "tf.keras.experimental.export_saved_model(model, export_path)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Face Recognition Transfer Learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
